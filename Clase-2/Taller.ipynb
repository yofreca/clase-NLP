{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "866cfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber  # Para extraer texto de PDFs\n",
    "import re  # Para trabajar con expresiones regulares\n",
    "import spacy  # Para procesamiento de lenguaje natural (NLP)\n",
    "import unicodedata  # Para normalizar caracteres Unicode\n",
    "import spacy\n",
    "import nltk\n",
    "import stanza\n",
    "from transformers import AutoTokenizer\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fef45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")  #cargar el modelo en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc62912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\John\n",
      "[nltk_data]     Fredy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\John\n",
      "[nltk_data]     Fredy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 433kB [00:00, 16.4MB/s]                    \n",
      "2025-08-20 21:20:31 INFO: Downloaded file to C:\\Users\\John Fredy\\stanza_resources\\resources.json\n",
      "2025-08-20 21:20:31 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2025-08-20 21:20:35 INFO: File exists: C:\\Users\\John Fredy\\stanza_resources\\es\\default.zip\n",
      "2025-08-20 21:20:52 INFO: Finished downloading models and saved to C:\\Users\\John Fredy\\stanza_resources\n",
      "2025-08-20 21:20:52 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 433kB [00:00, 16.4MB/s]                    \n",
      "2025-08-20 21:20:52 INFO: Downloaded file to C:\\Users\\John Fredy\\stanza_resources\\resources.json\n",
      "2025-08-20 21:20:57 INFO: Loading these models for language: es (Spanish):\n",
      "====================================\n",
      "| Processor    | Package           |\n",
      "------------------------------------\n",
      "| tokenize     | combined          |\n",
      "| mwt          | combined          |\n",
      "| pos          | combined_charlm   |\n",
      "| lemma        | combined_nocharlm |\n",
      "| constituency | combined_charlm   |\n",
      "| depparse     | combined_charlm   |\n",
      "| sentiment    | tass2020_charlm   |\n",
      "| ner          | conll02           |\n",
      "====================================\n",
      "\n",
      "2025-08-20 21:20:57 INFO: Using device: cpu\n",
      "2025-08-20 21:20:57 INFO: Loading: tokenize\n",
      "2025-08-20 21:20:57 INFO: Loading: mwt\n",
      "2025-08-20 21:20:57 INFO: Loading: pos\n",
      "2025-08-20 21:21:15 INFO: Loading: lemma\n",
      "2025-08-20 21:21:26 INFO: Loading: constituency\n",
      "2025-08-20 21:21:30 INFO: Loading: depparse\n",
      "2025-08-20 21:21:32 INFO: Loading: sentiment\n",
      "2025-08-20 21:21:34 INFO: Loading: ner\n",
      "2025-08-20 21:21:48 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stanza.download('es')\n",
    "nlp_stanza = stanza.Pipeline('es')\n",
    "nlp_spacy = spacy.load('es_core_news_sm')\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4383b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "876021c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../Archivos/NTIC_SXXI.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b59d4",
   "metadata": {},
   "source": [
    "## Funciones de limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5c3047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header_by_position(pdf_path, header_height=100):\n",
    "    \"\"\"\n",
    "    Elimina texto que aparece en la parte superior de cada página\n",
    "    basándose en coordenadas Y (posición vertical)\n",
    "    \"\"\"\n",
    "    extracted_text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_height = page.height\n",
    "            # Filtrar solo texto que NO esté en el área del encabezado\n",
    "            filtered_text = \"\"\n",
    "            \n",
    "            if page.chars:  # Si hay caracteres en la página\n",
    "                for char in page.chars:\n",
    "                    # Si el carácter está por debajo del área del encabezado\n",
    "                    if char['y1'] < (page_height - header_height):\n",
    "                        filtered_text += char['text']\n",
    "                        \n",
    "            extracted_text.append(filtered_text)\n",
    "    \n",
    "    return \" \".join(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56e2d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_footer_by_regex(text):\n",
    "    \"\"\"\n",
    "    Elimina pie de página usando expresiones regulares específicas\n",
    "    Parámetros:\n",
    "        text (str): Texto del cual eliminar el pie de página\n",
    "    Retorna:\n",
    "        str: Texto sin pie de página\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Patrón para el pie de página específico que mencionaste\n",
    "    footer_pattern = r\"http://www\\.ugr\\.es/~sevimeco/revistaeticanet/index\\.htm\\s*Rocío Domínguez Alfonso\"\n",
    "    \n",
    "    # Patrones genéricos comunes en pies de página\n",
    "    generic_footer_patterns = [\n",
    "        r\"Página\\s+\\d+\\s+de\\s+\\d+\",  # \"Página X de Y\"\n",
    "        r\"\\d+\\s*/\\s*\\d+\",             # \"1/10\"\n",
    "        r\"www\\.[^\\s]+\\.com\",          # URLs web\n",
    "        r\"http[s]?://[^\\s]+\",         # URLs completas\n",
    "        r\"©\\s*\\d{4}.*\",               # Copyright\n",
    "        r\"Todos los derechos reservados.*\",\n",
    "        r\"Confidencial.*\",\n",
    "        r\"\\d{2}/\\d{2}/\\d{4}.*\",       # Fechas\n",
    "    ]\n",
    "    \n",
    "    # Eliminar pie de página específico\n",
    "    cleaned_text = re.sub(footer_pattern, \"\", text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # Eliminar patrones genéricos de pie de página\n",
    "    for pattern in generic_footer_patterns:\n",
    "        cleaned_text = re.sub(pattern, \"\", cleaned_text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # Limpiar líneas vacías extras y espacios\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)  # Normalizar caracteres Unicode (ej. á → a)\n",
    "\n",
    "    text = nlp(text.lower())  # Convertir todo el texto a minúsculas y procesarlo con spaCy\n",
    "\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "174d2302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nuevas', 'Tecnologías', 'Educación', 'siglo', 'XXI', 'Rocío', 'Domínguez', 'Alfonso', 'Licenciada', 'Pedagogía', 'Doctoranda', 'Departamento', 'Didáctica', 'Organización', 'Escolar', 'Universidad', 'Granada', 'RESUMEN:', 'En', 'dos', 'últimas', 'décadas', 'autores', 'investigadores', 'acuñado', 'término', '“Sociedad', 'información”', 'referirse', 'serie', 'conjunto', 'transformaciones', 'económicas,', 'sociales,', 'culturales...', 'cambiarán', 'forma', 'sustancial', 'sociedad.', 'Quizá', 'transformación', 'más', 'espectacular', 'ofrecida', 'introducción', 'generalizada', 'nuevas', 'tecnologías', 'información', 'comunicación']\n"
     ]
    }
   ],
   "source": [
    "raw_text = remove_header_by_position(pdf_path,150)  # Extraer texto limpio del PDF\n",
    "pdf_text = remove_footer_by_regex(raw_text)  # Eliminar pies de página\n",
    "tokens = preprocess_text(pdf_text)\n",
    "\n",
    "print(tokens[:50])  # Mostrar los primeros 50 tokens como prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "519322ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Resultado/taller_clase2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(pdf_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895a1f1",
   "metadata": {},
   "source": [
    "#Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b47e0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\John\n",
      "[nltk_data]     Fredy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the necessary data for Spanish tokenization\n",
    "nltk.download('punkt', quiet=True)\n",
    "# nltk.download('spanish_grammars')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2734bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tokenización con diferentes librerías\n",
    "\n",
    "def tokenizar_spacy(texto):\n",
    "    return [token.text for token in nlp_spacy(texto)]\n",
    "\n",
    "def tokenizar_nltk(texto):\n",
    "    return nltk.word_tokenize(texto)\n",
    "\n",
    "def tokenizar_stanza(texto):\n",
    "    doc = nlp_stanza(texto)\n",
    "    return [word.text for sent in doc.sentences for word in sent.words]\n",
    "\n",
    "def tokenizar_bert(texto):\n",
    "    return tokenizer_bert.tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b61d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos cada método\n",
    "tokens_spacy = tokenizar_spacy(pdf_text)\n",
    "tokens_nltk = tokenizar_nltk(pdf_text)\n",
    "tokens_stanza = tokenizar_stanza(pdf_text)\n",
    "#tokens_bert = tokenizar_bert(texto_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5f5f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokens con SpaCy: ['Nuevas', 'Tecnologías', 'y', 'Educación', 'en', 'el', 'siglo', 'XXI', '  ', 'Rocío', 'Domínguez', 'Alfonso', 'Licenciada', 'en', 'Pedagogía', 'y', 'Doctoranda', 'del', 'Departamento', 'de']\n",
      "\n",
      "Tokens con NLTK: ['Nuevas', 'Tecnologías', 'y', 'Educación', 'en', 'el', 'siglo', 'XXI', 'Rocío', 'Domínguez', 'Alfonso', 'Licenciada', 'en', 'Pedagogía', 'y', 'Doctoranda', 'del', 'Departamento', 'de', 'Didáctica']\n",
      "\n",
      "Tokens con Stanza: ['Nuevas', 'Tecnologías', 'y', 'Educación', 'en', 'el', 'siglo', 'XXI', 'Rocío', 'Domínguez', 'Alfonso', 'Licenciada', 'en', 'Pedagogía', 'y', 'Doctoranda', 'de', 'el', 'Departamento', 'de']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los primeros 20 tokens de cada método\n",
    "print(\"\\nTokens con SpaCy:\", tokens_spacy[:20])\n",
    "print(\"\\nTokens con NLTK:\", tokens_nltk[:20])\n",
    "print(\"\\nTokens con Stanza:\", tokens_stanza[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ddc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_flair(text):\n",
    "    \"\"\"Lematizar texto usando Flair\"\"\"\n",
    "    tagger = SequenceTagger.load('pos-fast')\n",
    "    sentence = Sentence(text)\n",
    "    tagger.predict(sentence)\n",
    "    lemmas = [token.text for token in sentence.tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "570bd320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-20 21:05:18,112 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
     ]
    }
   ],
   "source": [
    "lemmas = lemmatize_with_flair(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e537ea38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lema</th>\n",
       "      <th>Frecuencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medios</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>más</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nuevas</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>formación</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tecnologías</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comunicación</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tecnologías</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>En</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>enseñanza</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cambios</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aprendizaje</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nuevas</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sociedad</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>información</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Las</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>La</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>educación</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>profesor</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>escuela</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>forma</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>alumnos</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>actitudes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>parte</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Internet</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>siglo</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>están</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ortega</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>también</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>si</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>proceso</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sino</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ser</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>El</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>hacia</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tipo</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cualquier</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>instituciones</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>contenidos</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>recursos</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pedagogía.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>desarrollo</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>práctica</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>diferentes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>medios,</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>medio</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>uso</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ed.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transformaciones</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>introducción</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>puede</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Lema  Frecuencia\n",
       "0             medios          25\n",
       "1               más          22\n",
       "2             Nuevas          21\n",
       "3         formación          21\n",
       "4       tecnologías          19\n",
       "5      comunicación          18\n",
       "6       Tecnologías          16\n",
       "7                 En          14\n",
       "8         enseñanza          14\n",
       "9            cambios          13\n",
       "10       aprendizaje          13\n",
       "11            nuevas          12\n",
       "12          sociedad          12\n",
       "13      información          11\n",
       "14               Las          11\n",
       "15                La          11\n",
       "16        educación          11\n",
       "17          profesor          11\n",
       "18           escuela          11\n",
       "19             forma          10\n",
       "20           alumnos           9\n",
       "21         actitudes           9\n",
       "22             parte           8\n",
       "23          Internet           8\n",
       "24             siglo           7\n",
       "25            están           7\n",
       "26            Ortega           7\n",
       "27          también           7\n",
       "28                si           7\n",
       "29           proceso           7\n",
       "30              sino           7\n",
       "31               ser           7\n",
       "32                El           7\n",
       "33             hacia           7\n",
       "34              tipo           7\n",
       "35         cualquier           6\n",
       "36     instituciones           6\n",
       "37        contenidos           6\n",
       "38          recursos           6\n",
       "39       Pedagogía.           6\n",
       "40        desarrollo           6\n",
       "41         práctica           6\n",
       "42        diferentes           6\n",
       "43           medios,           6\n",
       "44             medio           6\n",
       "45               uso           6\n",
       "46               Ed.           6\n",
       "47  transformaciones           5\n",
       "48     introducción           5\n",
       "49             puede           5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_counts = Counter(lemmas).most_common(100)\n",
    "df = pd.DataFrame(lemma_counts, columns=['Lema', 'Frecuencia'])\n",
    "\n",
    "df.head(50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c136358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar y guardar resultados\n",
    "df.to_csv('../Resultado/lemmas_flair_top100.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6d756",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb270fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "e:\\Universidad\\Maestria\\Semestre 4\\Minería de texto\\Codigo\\clase-NLP\\my-env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\John Fredy\\.flair\\models\\ner-spanish-large\\models--flair--ner-spanish-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-20 21:30:02,098 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-LOC, S-ORG, B-PER, I-PER, E-PER, S-MISC, B-ORG, E-ORG, S-PER, I-ORG, B-LOC, E-LOC, B-MISC, E-MISC, I-MISC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# Introduce tu token aquí\n",
    "token = \"\"\n",
    "\n",
    "login(token=token)\n",
    "\n",
    "tagger = SequenceTagger.load('flair/ner-spanish-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1b9a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aplicar NER con Flair\n",
    "def apply_ner(text):\n",
    "    sentence = Sentence(text)\n",
    "    tagger.predict(sentence)\n",
    "    entities = [(entity.text, entity.labels[0].value) for entity in sentence.get_spans('ner')]\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45a71050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entities(entities):\n",
    "    counter = Counter(entities)\n",
    "    data = [{'Entidad': ent, 'Tipo': typ, 'Frecuencia': freq} for (ent, typ), freq in counter.items()]\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28036882",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = apply_ner(tokens)\n",
    "result_df = count_entities(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7b40499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Entidad  Tipo  Frecuencia\n",
      "0        Nuevas Tecnologías Educación siglo XXI  MISC           1\n",
      "1                       Rocío Domínguez Alfonso   PER           1\n",
      "2   Departamento Didáctica Organización Escolar   ORG           1\n",
      "3                             Universidad Granada   ORG           1\n",
      "4                                 Ortega Carrillo   PER           3\n",
      "..                                            ...   ...         ...\n",
      "85                             Escuela Española.   ORG           1\n",
      "86                 Sociedad Española Pedagogía.   ORG           1\n",
      "87                               Sevillano, Ma L.   PER           2\n",
      "88             Tecnologías, medios comunicación  MISC           2\n",
      "89                                           CCS.   ORG           2\n",
      "\n",
      "[90 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "166cea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel('../Resultado/NER_Frecuencias.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
